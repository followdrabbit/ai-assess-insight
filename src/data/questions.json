{
  "questions": [
    {
      "questionId": "GOV-01-Q01",
      "subcatId": "GOV-01",
      "domainId": "GOV",
      "questionText": "Existe uma política formal documentada para uso de IA na organização?",
      "expectedEvidence": "Documento de política aprovado pela alta gestão, com data de vigência e responsáveis definidos",
      "imperativeChecks": "Verificar aprovação formal, data de última revisão, distribuição para stakeholders",
      "riskSummary": "Ausência de política pode levar a uso inconsistente e inseguro de IA",
      "frameworks": ["NIST AI RMF - GOVERN 1.1", "ISO/IEC 42001 - 5.1"]
    },
    {
      "questionId": "GOV-01-Q02",
      "subcatId": "GOV-01",
      "domainId": "GOV",
      "questionText": "A política de IA inclui requisitos específicos de segurança da informação?",
      "expectedEvidence": "Seções da política abordando confidencialidade, integridade e disponibilidade",
      "imperativeChecks": "Verificar alinhamento com política de segurança corporativa",
      "riskSummary": "Política sem requisitos de segurança não protege adequadamente ativos",
      "frameworks": ["ISO 27001 - A.5.1", "NIST AI RMF - GOVERN 1.2"]
    },
    {
      "questionId": "GOV-01-Q03",
      "subcatId": "GOV-01",
      "domainId": "GOV",
      "questionText": "Existem procedimentos operacionais documentados para projetos de IA?",
      "expectedEvidence": "SOPs ou runbooks para desenvolvimento, deploy e operação de modelos",
      "imperativeChecks": "Verificar completude, atualização e aderência nos projetos ativos",
      "riskSummary": "Sem procedimentos, cada equipe opera de forma inconsistente",
      "frameworks": ["NIST AI RMF - GOVERN 2.1", "ISO/IEC 42001 - 7.5"]
    },
    {
      "questionId": "GOV-01-Q04",
      "subcatId": "GOV-01",
      "domainId": "GOV",
      "questionText": "As políticas de IA são revisadas periodicamente (ao menos anualmente)?",
      "expectedEvidence": "Registro de revisões com datas, responsáveis e mudanças realizadas",
      "imperativeChecks": "Verificar última data de revisão e gatilhos para revisão extraordinária",
      "riskSummary": "Políticas desatualizadas não refletem novos riscos e tecnologias",
      "frameworks": ["ISO 27001 - 5.3", "NIST AI RMF - GOVERN 1.5"]
    },
    {
      "questionId": "GOV-02-Q01",
      "subcatId": "GOV-02",
      "domainId": "GOV",
      "questionText": "Existe um comitê ou função responsável por governança de IA?",
      "expectedEvidence": "Organograma ou charter do comitê com membros e responsabilidades",
      "imperativeChecks": "Verificar frequência de reuniões e atas de decisões",
      "riskSummary": "Sem governança formal, decisões de IA são descentralizadas e inconsistentes",
      "frameworks": ["NIST AI RMF - GOVERN 2.2", "ISO/IEC 42001 - 5.3"]
    },
    {
      "questionId": "GOV-02-Q02",
      "subcatId": "GOV-02",
      "domainId": "GOV",
      "questionText": "Os papéis de segurança em projetos de IA estão claramente definidos?",
      "expectedEvidence": "Matriz RACI ou descrições de cargo incluindo responsabilidades de segurança",
      "imperativeChecks": "Verificar se todos os projetos têm responsável de segurança designado",
      "riskSummary": "Responsabilidades ambíguas levam a gaps de segurança",
      "frameworks": ["ISO 27001 - 5.3", "NIST AI RMF - GOVERN 2.3"]
    },
    {
      "questionId": "GOV-02-Q03",
      "subcatId": "GOV-02",
      "domainId": "GOV",
      "questionText": "Existe processo de escalação para decisões críticas de IA?",
      "expectedEvidence": "Fluxograma ou procedimento de escalação documentado",
      "imperativeChecks": "Verificar critérios de escalação e tempo de resposta definido",
      "riskSummary": "Sem escalação clara, problemas críticos podem não ser tratados a tempo",
      "frameworks": ["NIST AI RMF - GOVERN 3.1", "ISO 27001 - A.16.1"]
    },
    {
      "questionId": "GOV-03-Q01",
      "subcatId": "GOV-03",
      "domainId": "GOV",
      "questionText": "Foi realizado mapeamento das regulamentações aplicáveis a IA na organização?",
      "expectedEvidence": "Inventário de regulamentações com análise de aplicabilidade",
      "imperativeChecks": "Verificar inclusão de LGPD, setoriais e internacionais se aplicável",
      "riskSummary": "Desconhecimento regulatório pode resultar em violações e multas",
      "frameworks": ["EU AI Act", "LGPD Art. 6", "NIST AI RMF - GOVERN 1.3"]
    },
    {
      "questionId": "GOV-03-Q02",
      "subcatId": "GOV-03",
      "domainId": "GOV",
      "questionText": "Existe processo para monitorar mudanças regulatórias em IA?",
      "expectedEvidence": "Procedimento ou serviço de monitoramento regulatório",
      "imperativeChecks": "Verificar frequência de atualização e responsável designado",
      "riskSummary": "Novas regulamentações podem tornar práticas atuais não conformes",
      "frameworks": ["ISO 27001 - 4.2", "NIST AI RMF - GOVERN 1.4"]
    },
    {
      "questionId": "GOV-03-Q03",
      "subcatId": "GOV-03",
      "domainId": "GOV",
      "questionText": "Os sistemas de IA de alto risco são classificados conforme requisitos do EU AI Act?",
      "expectedEvidence": "Classificação de sistemas por nível de risco com justificativa",
      "imperativeChecks": "Verificar metodologia de classificação e revisão periódica",
      "riskSummary": "Classificação incorreta pode resultar em não conformidade",
      "frameworks": ["EU AI Act Art. 6", "NIST AI RMF - MAP 1.1"]
    },
    {
      "questionId": "DATA-01-Q01",
      "subcatId": "DATA-01",
      "domainId": "DATA",
      "questionText": "Existe esquema de classificação de dados aplicado a datasets de IA?",
      "expectedEvidence": "Política de classificação com níveis definidos e critérios",
      "imperativeChecks": "Verificar aplicação em datasets de treinamento e produção",
      "riskSummary": "Dados não classificados podem ser tratados inadequadamente",
      "frameworks": ["ISO 27001 - A.8.2", "NIST AI RMF - MAP 2.1"]
    },
    {
      "questionId": "DATA-01-Q02",
      "subcatId": "DATA-01",
      "domainId": "DATA",
      "questionText": "Os datasets de treinamento são inventariados e rastreados?",
      "expectedEvidence": "Catálogo de dados com metadados de origem, sensibilidade e uso",
      "imperativeChecks": "Verificar atualização do inventário e cobertura de datasets ativos",
      "riskSummary": "Datasets não rastreados dificultam auditoria e compliance",
      "frameworks": ["NIST AI RMF - MAP 2.2", "ISO/IEC 42001 - 6.1"]
    },
    {
      "questionId": "DATA-01-Q03",
      "subcatId": "DATA-01",
      "domainId": "DATA",
      "questionText": "Existe processo para identificar dados pessoais em datasets de IA?",
      "expectedEvidence": "Procedimento de discovery de dados pessoais, ferramentas utilizadas",
      "imperativeChecks": "Verificar execução em novos datasets e periodicidade de revisão",
      "riskSummary": "Dados pessoais não identificados podem violar LGPD/GDPR",
      "frameworks": ["LGPD Art. 5", "GDPR Art. 4", "NIST Privacy Framework"]
    },
    {
      "questionId": "DATA-02-Q01",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Existe base legal documentada para tratamento de dados pessoais em IA?",
      "expectedEvidence": "Registro de bases legais por finalidade de tratamento",
      "imperativeChecks": "Verificar alinhamento com inventário de dados e ROPA",
      "riskSummary": "Tratamento sem base legal é violação de privacidade",
      "frameworks": ["LGPD Art. 7", "GDPR Art. 6", "NIST Privacy Framework"]
    },
    {
      "questionId": "DATA-02-Q02",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Os titulares são informados sobre uso de seus dados em sistemas de IA?",
      "expectedEvidence": "Avisos de privacidade mencionando uso de IA, transparência algorítmica",
      "imperativeChecks": "Verificar clareza e acessibilidade das informações",
      "riskSummary": "Falta de transparência viola direitos dos titulares",
      "frameworks": ["LGPD Art. 9", "GDPR Art. 13-14", "EU AI Act Art. 52"]
    },
    {
      "questionId": "DATA-02-Q03",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Existe processo para atender direitos de titulares (acesso, exclusão, etc.)?",
      "expectedEvidence": "Procedimento documentado, canal de atendimento, SLA definido",
      "imperativeChecks": "Verificar capacidade de identificar e excluir dados de IA",
      "riskSummary": "Incapacidade de atender direitos gera sanções regulatórias",
      "frameworks": ["LGPD Art. 18", "GDPR Art. 15-22"]
    },
    {
      "questionId": "DATA-03-Q01",
      "subcatId": "DATA-03",
      "domainId": "DATA",
      "questionText": "Existem métricas de qualidade de dados para datasets de IA?",
      "expectedEvidence": "KPIs de qualidade (completude, acurácia, consistência) definidos e medidos",
      "imperativeChecks": "Verificar thresholds mínimos e ações para dados fora do padrão",
      "riskSummary": "Dados de baixa qualidade comprometem performance e fairness",
      "frameworks": ["NIST AI RMF - MAP 2.3", "ISO 8000"]
    },
    {
      "questionId": "DATA-03-Q02",
      "subcatId": "DATA-03",
      "domainId": "DATA",
      "questionText": "Os dados de treinamento são validados quanto a vieses?",
      "expectedEvidence": "Análises de fairness, distribuição demográfica, testes de viés",
      "imperativeChecks": "Verificar metodologia e frequência de análise",
      "riskSummary": "Dados enviesados produzem modelos discriminatórios",
      "frameworks": ["NIST AI RMF - MEASURE 2.6", "EU AI Act Art. 10"]
    },
    {
      "questionId": "DATA-03-Q03",
      "subcatId": "DATA-03",
      "domainId": "DATA",
      "questionText": "Existe processo de limpeza e preparação de dados documentado?",
      "expectedEvidence": "Pipeline de data prep com etapas, validações e logs",
      "imperativeChecks": "Verificar reprodutibilidade e rastreabilidade",
      "riskSummary": "Processo ad-hoc dificulta auditoria e reprodução",
      "frameworks": ["NIST AI RMF - MAP 2.4", "MLOps Best Practices"]
    },
    {
      "questionId": "DATA-04-Q01",
      "subcatId": "DATA-04",
      "domainId": "DATA",
      "questionText": "Existe política de retenção específica para dados de IA?",
      "expectedEvidence": "Política com prazos por tipo de dado e justificativa",
      "imperativeChecks": "Verificar alinhamento com LGPD e necessidade do negócio",
      "riskSummary": "Retenção indefinida viola princípio de minimização",
      "frameworks": ["LGPD Art. 16", "GDPR Art. 5(1)(e)", "ISO 27001 - A.8.3"]
    },
    {
      "questionId": "DATA-04-Q02",
      "subcatId": "DATA-04",
      "domainId": "DATA",
      "questionText": "Os dados de treinamento obsoletos são descartados de forma segura?",
      "expectedEvidence": "Procedimento de descarte, logs de exclusão, certificados",
      "imperativeChecks": "Verificar execução do descarte e rastreabilidade",
      "riskSummary": "Dados não descartados adequadamente podem ser expostos",
      "frameworks": ["ISO 27001 - A.8.3", "NIST SP 800-88"]
    },
    {
      "questionId": "MODEL-01-Q01",
      "subcatId": "MODEL-01",
      "domainId": "MODEL",
      "questionText": "O ambiente de desenvolvimento de ML é segregado do ambiente de produção?",
      "expectedEvidence": "Diagrama de arquitetura mostrando segregação, controles de acesso",
      "imperativeChecks": "Verificar impossibilidade de acesso direto dev-prod",
      "riskSummary": "Ambientes misturados permitem comprometimento de produção",
      "frameworks": ["NIST AI RMF - MANAGE 2.1", "ISO 27001 - A.12.1"]
    },
    {
      "questionId": "MODEL-01-Q02",
      "subcatId": "MODEL-01",
      "domainId": "MODEL",
      "questionText": "O código de treinamento passa por revisão de segurança?",
      "expectedEvidence": "Processo de code review, checklist de segurança, ferramentas SAST",
      "imperativeChecks": "Verificar cobertura e frequência de revisões",
      "riskSummary": "Código não revisado pode conter vulnerabilidades",
      "frameworks": ["OWASP ML Top 10", "NIST AI RMF - MANAGE 2.2"]
    },
    {
      "questionId": "MODEL-01-Q03",
      "subcatId": "MODEL-01",
      "domainId": "MODEL",
      "questionText": "As dependências do pipeline de ML são verificadas quanto a vulnerabilidades?",
      "expectedEvidence": "Scans de dependências, SBOMs, processo de atualização",
      "imperativeChecks": "Verificar frequência de scans e tratamento de vulnerabilidades",
      "riskSummary": "Dependências vulneráveis podem comprometer o pipeline",
      "frameworks": ["NIST SSDF", "OWASP Dependency Check", "MITRE ATLAS"]
    },
    {
      "questionId": "MODEL-01-Q04",
      "subcatId": "MODEL-01",
      "domainId": "MODEL",
      "questionText": "Existe proteção contra data poisoning no pipeline de treinamento?",
      "expectedEvidence": "Controles de integridade de dados, validações, detecção de anomalias",
      "imperativeChecks": "Verificar implementação e testes de eficácia",
      "riskSummary": "Data poisoning pode inserir backdoors no modelo",
      "frameworks": ["MITRE ATLAS - AML.T0020", "NIST AI RMF - MEASURE 2.5"]
    },
    {
      "questionId": "MODEL-02-Q01",
      "subcatId": "MODEL-02",
      "domainId": "MODEL",
      "questionText": "Os modelos são testados contra ataques adversariais?",
      "expectedEvidence": "Resultados de testes adversariais, metodologia utilizada",
      "imperativeChecks": "Verificar tipos de ataques testados e frequência",
      "riskSummary": "Modelos não testados são vulneráveis a evasão",
      "frameworks": ["MITRE ATLAS - AML.T0015", "NIST AI RMF - MEASURE 2.7"]
    },
    {
      "questionId": "MODEL-02-Q02",
      "subcatId": "MODEL-02",
      "domainId": "MODEL",
      "questionText": "Existem defesas implementadas contra adversarial examples?",
      "expectedEvidence": "Técnicas de defesa (adversarial training, input validation, etc.)",
      "imperativeChecks": "Verificar eficácia das defesas e cobertura",
      "riskSummary": "Sem defesas, atacantes podem manipular outputs",
      "frameworks": ["MITRE ATLAS", "NIST AI RMF - MANAGE 2.3"]
    },
    {
      "questionId": "MODEL-02-Q03",
      "subcatId": "MODEL-02",
      "domainId": "MODEL",
      "questionText": "O modelo detecta e rejeita inputs anômalos ou fora de distribuição?",
      "expectedEvidence": "Mecanismos de OOD detection, thresholds definidos, logs",
      "imperativeChecks": "Verificar taxa de detecção e falsos positivos",
      "riskSummary": "Inputs anômalos podem causar comportamento inesperado",
      "frameworks": ["NIST AI RMF - MEASURE 2.8", "MITRE ATLAS - AML.T0043"]
    },
    {
      "questionId": "MODEL-03-Q01",
      "subcatId": "MODEL-03",
      "domainId": "MODEL",
      "questionText": "Os modelos são versionados com controle formal?",
      "expectedEvidence": "Sistema de versionamento (MLflow, DVC, etc.), histórico de versões",
      "imperativeChecks": "Verificar capacidade de recuperar qualquer versão anterior",
      "riskSummary": "Sem versionamento, rollback é impossível",
      "frameworks": ["NIST AI RMF - GOVERN 4.1", "MLOps Best Practices"]
    },
    {
      "questionId": "MODEL-03-Q02",
      "subcatId": "MODEL-03",
      "domainId": "MODEL",
      "questionText": "Os experimentos de ML são registrados com metadados completos?",
      "expectedEvidence": "Logs de experimentos com hiperparâmetros, métricas, datasets usados",
      "imperativeChecks": "Verificar completude dos registros e acessibilidade",
      "riskSummary": "Experimentos não documentados não são reproduzíveis",
      "frameworks": ["NIST AI RMF - GOVERN 4.2", "ISO/IEC 42001 - 7.5"]
    },
    {
      "questionId": "MODEL-03-Q03",
      "subcatId": "MODEL-03",
      "domainId": "MODEL",
      "questionText": "Os modelos em produção podem ser rastreados até seus dados de origem?",
      "expectedEvidence": "Lineage tracking, documentação de proveniência",
      "imperativeChecks": "Verificar capacidade de auditoria end-to-end",
      "riskSummary": "Sem rastreabilidade, investigações são impossíveis",
      "frameworks": ["NIST AI RMF - GOVERN 4.3", "EU AI Act Art. 12"]
    },
    {
      "questionId": "MODEL-04-Q01",
      "subcatId": "MODEL-04",
      "domainId": "MODEL",
      "questionText": "Os modelos de alto risco possuem documentação de explicabilidade?",
      "expectedEvidence": "Model cards, documentação de limitações, explicações de decisões",
      "imperativeChecks": "Verificar completude e atualização da documentação",
      "riskSummary": "Modelos inexplicáveis não podem ser auditados",
      "frameworks": ["EU AI Act Art. 13", "NIST AI RMF - MEASURE 2.9"]
    },
    {
      "questionId": "MODEL-04-Q02",
      "subcatId": "MODEL-04",
      "domainId": "MODEL",
      "questionText": "Existem técnicas de XAI implementadas para decisões importantes?",
      "expectedEvidence": "Implementação de SHAP, LIME ou similar, interface de explicação",
      "imperativeChecks": "Verificar qualidade das explicações e usabilidade",
      "riskSummary": "Decisões sem explicação podem ser contestadas",
      "frameworks": ["NIST AI RMF - MEASURE 2.10", "EU AI Act Art. 14"]
    },
    {
      "questionId": "MODEL-04-Q03",
      "subcatId": "MODEL-04",
      "domainId": "MODEL",
      "questionText": "Os usuários podem contestar decisões automatizadas?",
      "expectedEvidence": "Canal de contestação, processo de revisão humana, SLA",
      "imperativeChecks": "Verificar efetividade do processo e tempo de resposta",
      "riskSummary": "Impossibilidade de contestar viola direitos dos afetados",
      "frameworks": ["LGPD Art. 20", "GDPR Art. 22", "EU AI Act Art. 14"]
    },
    {
      "questionId": "INFRA-01-Q01",
      "subcatId": "INFRA-01",
      "domainId": "INFRA",
      "questionText": "Os ambientes de IA utilizam imagens base hardened?",
      "expectedEvidence": "Baseline de hardening, processo de atualização de imagens",
      "imperativeChecks": "Verificar conformidade com CIS Benchmarks ou similar",
      "riskSummary": "Imagens não hardened contêm vulnerabilidades conhecidas",
      "frameworks": ["CIS Benchmarks", "NIST SP 800-123"]
    },
    {
      "questionId": "INFRA-01-Q02",
      "subcatId": "INFRA-01",
      "domainId": "INFRA",
      "questionText": "Os modelos em produção executam em containers isolados?",
      "expectedEvidence": "Arquitetura containerizada, políticas de network isolation",
      "imperativeChecks": "Verificar isolamento e políticas de rede",
      "riskSummary": "Falta de isolamento permite movimentação lateral",
      "frameworks": ["NIST SP 800-190", "CIS Docker Benchmark"]
    },
    {
      "questionId": "INFRA-01-Q03",
      "subcatId": "INFRA-01",
      "domainId": "INFRA",
      "questionText": "Existe processo de patch management para infraestrutura de IA?",
      "expectedEvidence": "Política de patching, cronograma, métricas de compliance",
      "imperativeChecks": "Verificar SLA de aplicação de patches críticos",
      "riskSummary": "Sistemas desatualizados são alvos fáceis",
      "frameworks": ["NIST CSF - PR.IP-12", "ISO 27001 - A.12.6"]
    },
    {
      "questionId": "INFRA-02-Q01",
      "subcatId": "INFRA-02",
      "domainId": "INFRA",
      "questionText": "O acesso a modelos e dados de IA utiliza autenticação forte (MFA)?",
      "expectedEvidence": "Configuração de MFA, política de autenticação",
      "imperativeChecks": "Verificar cobertura de todos os acessos sensíveis",
      "riskSummary": "Autenticação fraca facilita acessos não autorizados",
      "frameworks": ["NIST SP 800-63B", "ISO 27001 - A.9.4"]
    },
    {
      "questionId": "INFRA-02-Q02",
      "subcatId": "INFRA-02",
      "domainId": "INFRA",
      "questionText": "Existe revisão periódica de acessos a recursos de IA?",
      "expectedEvidence": "Processo de access review, registros de revisões, ações corretivas",
      "imperativeChecks": "Verificar frequência e cobertura das revisões",
      "riskSummary": "Acessos obsoletos aumentam superfície de ataque",
      "frameworks": ["ISO 27001 - A.9.2.5", "NIST CSF - PR.AC-1"]
    },
    {
      "questionId": "INFRA-02-Q03",
      "subcatId": "INFRA-02",
      "domainId": "INFRA",
      "questionText": "APIs de inferência possuem rate limiting e throttling?",
      "expectedEvidence": "Configuração de rate limits, alertas de abuso",
      "imperativeChecks": "Verificar limites por usuário/IP e tratamento de violações",
      "riskSummary": "Sem rate limiting, APIs são vulneráveis a DoS e extração",
      "frameworks": ["OWASP API Security Top 10", "NIST AI RMF - MANAGE 3.1"]
    },
    {
      "questionId": "INFRA-02-Q04",
      "subcatId": "INFRA-02",
      "domainId": "INFRA",
      "questionText": "Os modelos proprietários são protegidos contra extração?",
      "expectedEvidence": "Controles anti-extração, watermarking, detecção de queries suspeitas",
      "imperativeChecks": "Verificar eficácia dos controles e monitoramento",
      "riskSummary": "Modelos podem ser roubados via queries sistemáticas",
      "frameworks": ["MITRE ATLAS - AML.T0024", "NIST AI RMF - MANAGE 3.2"]
    },
    {
      "questionId": "INFRA-03-Q01",
      "subcatId": "INFRA-03",
      "domainId": "INFRA",
      "questionText": "Existe monitoramento de drift de modelo em produção?",
      "expectedEvidence": "Sistema de monitoramento de drift, alertas configurados, dashboards",
      "imperativeChecks": "Verificar métricas monitoradas e thresholds de alerta",
      "riskSummary": "Drift não detectado degrada performance e segurança",
      "frameworks": ["NIST AI RMF - MEASURE 4.1", "MLOps Best Practices"]
    },
    {
      "questionId": "INFRA-03-Q02",
      "subcatId": "INFRA-03",
      "domainId": "INFRA",
      "questionText": "Os logs de inferência são coletados e retidos?",
      "expectedEvidence": "Configuração de logging, período de retenção, proteção de logs",
      "imperativeChecks": "Verificar completude dos logs e proteção contra tampering",
      "riskSummary": "Sem logs, investigações forenses são impossíveis",
      "frameworks": ["ISO 27001 - A.12.4", "NIST CSF - DE.CM"]
    },
    {
      "questionId": "INFRA-03-Q03",
      "subcatId": "INFRA-03",
      "domainId": "INFRA",
      "questionText": "Existe detecção de anomalias no comportamento de modelos?",
      "expectedEvidence": "Sistema de detecção de anomalias, baseline definido, alertas",
      "imperativeChecks": "Verificar tipos de anomalias detectadas e tempo de resposta",
      "riskSummary": "Comportamento anômalo pode indicar ataque em curso",
      "frameworks": ["NIST AI RMF - MEASURE 4.2", "MITRE ATLAS - AML.T0048"]
    },
    {
      "questionId": "INFRA-04-Q01",
      "subcatId": "INFRA-04",
      "domainId": "INFRA",
      "questionText": "Existe backup regular de modelos e artefatos de ML?",
      "expectedEvidence": "Política de backup, frequência, testes de restore",
      "imperativeChecks": "Verificar RTO/RPO definidos e capacidade de restore",
      "riskSummary": "Perda de modelos pode interromper operações críticas",
      "frameworks": ["ISO 27001 - A.12.3", "NIST CSF - PR.IP-4"]
    },
    {
      "questionId": "INFRA-04-Q02",
      "subcatId": "INFRA-04",
      "domainId": "INFRA",
      "questionText": "Existe plano de disaster recovery para sistemas de IA críticos?",
      "expectedEvidence": "Plano de DR documentado, cenários testados, responsáveis definidos",
      "imperativeChecks": "Verificar testes realizados e tempo de recuperação",
      "riskSummary": "Sem DR, falhas podem ter impacto prolongado",
      "frameworks": ["ISO 22301", "NIST CSF - PR.IP-9"]
    },
    {
      "questionId": "RISK-01-Q01",
      "subcatId": "RISK-01",
      "domainId": "RISK",
      "questionText": "Existe processo formal de avaliação de riscos para projetos de IA?",
      "expectedEvidence": "Metodologia de risk assessment, templates, registros de avaliações",
      "imperativeChecks": "Verificar cobertura de projetos e atualização periódica",
      "riskSummary": "Riscos não avaliados não podem ser tratados adequadamente",
      "frameworks": ["NIST AI RMF - MAP 1.1", "ISO 31000", "ISO/IEC 42001 - 6.1"]
    },
    {
      "questionId": "RISK-01-Q02",
      "subcatId": "RISK-01",
      "domainId": "RISK",
      "questionText": "Os riscos de IA são categorizados e priorizados?",
      "expectedEvidence": "Matriz de riscos, critérios de classificação, registro de riscos",
      "imperativeChecks": "Verificar atualização do registro e cobertura de categorias",
      "riskSummary": "Sem priorização, recursos são mal alocados",
      "frameworks": ["NIST AI RMF - MAP 1.2", "ISO 31000"]
    },
    {
      "questionId": "RISK-01-Q03",
      "subcatId": "RISK-01",
      "domainId": "RISK",
      "questionText": "Existe avaliação de impacto algorítmico (AIA) para sistemas de alto risco?",
      "expectedEvidence": "Relatórios de AIA, metodologia, ações de mitigação",
      "imperativeChecks": "Verificar completude e revisão por terceiros se aplicável",
      "riskSummary": "AIAs inadequadas podem não identificar riscos críticos",
      "frameworks": ["EU AI Act Art. 9", "NIST AI RMF - MAP 1.5"]
    },
    {
      "questionId": "RISK-01-Q04",
      "subcatId": "RISK-01",
      "domainId": "RISK",
      "questionText": "Os riscos identificados têm planos de tratamento definidos?",
      "expectedEvidence": "Planos de tratamento, responsáveis, prazos, status de implementação",
      "imperativeChecks": "Verificar execução dos planos e eficácia das mitigações",
      "riskSummary": "Riscos identificados sem tratamento permanecem ativos",
      "frameworks": ["ISO 31000", "NIST AI RMF - MANAGE 1.1"]
    },
    {
      "questionId": "RISK-02-Q01",
      "subcatId": "RISK-02",
      "domainId": "RISK",
      "questionText": "Existe plano de resposta a incidentes específico para IA?",
      "expectedEvidence": "Playbook de IR para IA, cenários, responsáveis, canais de comunicação",
      "imperativeChecks": "Verificar cobertura de cenários de IA (data poisoning, evasion, etc.)",
      "riskSummary": "Sem playbook específico, resposta será improvisada",
      "frameworks": ["NIST CSF - RS.RP", "ISO 27001 - A.16", "NIST AI RMF - MANAGE 4.1"]
    },
    {
      "questionId": "RISK-02-Q02",
      "subcatId": "RISK-02",
      "domainId": "RISK",
      "questionText": "A equipe de IR é treinada em incidentes de segurança de IA?",
      "expectedEvidence": "Registros de treinamento, exercícios realizados, competências definidas",
      "imperativeChecks": "Verificar frequência de treinamentos e cobertura da equipe",
      "riskSummary": "Equipe não treinada responderá inadequadamente",
      "frameworks": ["NIST CSF - RS.CO", "ISO 27001 - A.7.2"]
    },
    {
      "questionId": "RISK-02-Q03",
      "subcatId": "RISK-02",
      "domainId": "RISK",
      "questionText": "Existe processo de post-mortem para incidentes de IA?",
      "expectedEvidence": "Template de post-mortem, registros de incidentes, lições aprendidas",
      "imperativeChecks": "Verificar implementação de melhorias identificadas",
      "riskSummary": "Sem post-mortem, mesmos erros se repetem",
      "frameworks": ["NIST CSF - RS.IM", "ISO 27001 - A.16.1.6"]
    },
    {
      "questionId": "RISK-03-Q01",
      "subcatId": "RISK-03",
      "domainId": "RISK",
      "questionText": "Fornecedores de IA são avaliados quanto a práticas de segurança?",
      "expectedEvidence": "Questionários de due diligence, requisitos contratuais, auditorias",
      "imperativeChecks": "Verificar processo de avaliação e frequência de revisão",
      "riskSummary": "Fornecedores inseguros introduzem riscos na cadeia",
      "frameworks": ["NIST AI RMF - GOVERN 6.1", "ISO 27001 - A.15"]
    },
    {
      "questionId": "RISK-03-Q02",
      "subcatId": "RISK-03",
      "domainId": "RISK",
      "questionText": "Existe inventário de modelos e componentes de IA de terceiros?",
      "expectedEvidence": "Inventário com origem, versão, licença, data de integração",
      "imperativeChecks": "Verificar completude e atualização do inventário",
      "riskSummary": "Componentes desconhecidos são pontos cegos de segurança",
      "frameworks": ["NIST AI RMF - MAP 3.1", "SBOM practices"]
    },
    {
      "questionId": "RISK-03-Q03",
      "subcatId": "RISK-03",
      "domainId": "RISK",
      "questionText": "Contratos com fornecedores de IA incluem cláusulas de segurança?",
      "expectedEvidence": "Cláusulas contratuais de segurança, SLAs, direitos de auditoria",
      "imperativeChecks": "Verificar cobertura de confidencialidade, integridade e notificação de incidentes",
      "riskSummary": "Sem cláusulas, não há obrigação contratual de segurança",
      "frameworks": ["ISO 27001 - A.15.1", "NIST AI RMF - GOVERN 6.2"]
    },
    {
      "questionId": "HUMAN-01-Q01",
      "subcatId": "HUMAN-01",
      "domainId": "HUMAN",
      "questionText": "Existe programa de treinamento em segurança de IA para desenvolvedores?",
      "expectedEvidence": "Currículo de treinamento, registros de participação, avaliações",
      "imperativeChecks": "Verificar frequência, cobertura e atualização do conteúdo",
      "riskSummary": "Desenvolvedores não treinados criam vulnerabilidades",
      "frameworks": ["NIST AI RMF - GOVERN 5.1", "ISO 27001 - A.7.2"]
    },
    {
      "questionId": "HUMAN-01-Q02",
      "subcatId": "HUMAN-01",
      "domainId": "HUMAN",
      "questionText": "Usuários de sistemas de IA recebem orientação sobre uso seguro?",
      "expectedEvidence": "Materiais de conscientização, guias de uso, comunicações periódicas",
      "imperativeChecks": "Verificar clareza das orientações e alcance da comunicação",
      "riskSummary": "Usuários desinformados podem expor dados ou modelos",
      "frameworks": ["NIST AI RMF - GOVERN 5.2", "ISO 27001 - A.7.2.2"]
    },
    {
      "questionId": "HUMAN-01-Q03",
      "subcatId": "HUMAN-01",
      "domainId": "HUMAN",
      "questionText": "Existe conscientização sobre riscos de prompt injection e jailbreaking?",
      "expectedEvidence": "Treinamentos específicos, exemplos práticos, políticas de uso",
      "imperativeChecks": "Verificar atualização do conteúdo com novas técnicas",
      "riskSummary": "Desconhecimento facilita ataques de prompt injection",
      "frameworks": ["OWASP LLM Top 10", "MITRE ATLAS - AML.T0051"]
    },
    {
      "questionId": "HUMAN-02-Q01",
      "subcatId": "HUMAN-02",
      "domainId": "HUMAN",
      "questionText": "Existe código de ética para uso e desenvolvimento de IA?",
      "expectedEvidence": "Documento de ética aprovado, princípios definidos, casos de aplicação",
      "imperativeChecks": "Verificar conhecimento pela organização e mecanismos de enforcement",
      "riskSummary": "Sem código de ética, decisões são inconsistentes",
      "frameworks": ["IEEE EAD", "NIST AI RMF - GOVERN 3.2", "EU AI Act Preâmbulo"]
    },
    {
      "questionId": "HUMAN-02-Q02",
      "subcatId": "HUMAN-02",
      "domainId": "HUMAN",
      "questionText": "Os modelos são avaliados quanto a vieses discriminatórios?",
      "expectedEvidence": "Relatórios de fairness testing, métricas de equidade, ações corretivas",
      "imperativeChecks": "Verificar grupos avaliados, métricas utilizadas e periodicidade",
      "riskSummary": "Vieses não detectados causam discriminação",
      "frameworks": ["EU AI Act Art. 10", "NIST AI RMF - MEASURE 2.6"]
    },
    {
      "questionId": "HUMAN-02-Q03",
      "subcatId": "HUMAN-02",
      "domainId": "HUMAN",
      "questionText": "Existe canal para reportar preocupações éticas sobre IA?",
      "expectedEvidence": "Canal de denúncias, proteção a denunciantes, processo de investigação",
      "imperativeChecks": "Verificar acessibilidade e tratamento de denúncias recebidas",
      "riskSummary": "Sem canal seguro, problemas éticos não são reportados",
      "frameworks": ["EU AI Act Art. 62", "ISO 37002"]
    },
    {
      "questionId": "HUMAN-03-Q01",
      "subcatId": "HUMAN-03",
      "domainId": "HUMAN",
      "questionText": "Sistemas de IA de alto risco permitem intervenção humana?",
      "expectedEvidence": "Mecanismos de override, logs de intervenções, treinamento de operadores",
      "imperativeChecks": "Verificar efetividade dos mecanismos e tempo de resposta",
      "riskSummary": "Sem override, erros de IA não podem ser corrigidos rapidamente",
      "frameworks": ["EU AI Act Art. 14", "NIST AI RMF - GOVERN 3.3"]
    },
    {
      "questionId": "HUMAN-03-Q02",
      "subcatId": "HUMAN-03",
      "domainId": "HUMAN",
      "questionText": "Existe processo de revisão humana para decisões automatizadas críticas?",
      "expectedEvidence": "Critérios para revisão humana, processo documentado, métricas de revisão",
      "imperativeChecks": "Verificar percentual de decisões revisadas e qualidade da revisão",
      "riskSummary": "Decisões críticas sem revisão podem causar danos significativos",
      "frameworks": ["LGPD Art. 20", "GDPR Art. 22", "EU AI Act Art. 14"]
    },
    {
      "questionId": "HUMAN-03-Q03",
      "subcatId": "HUMAN-03",
      "domainId": "HUMAN",
      "questionText": "Os operadores humanos são treinados para supervisionar sistemas de IA?",
      "expectedEvidence": "Programa de treinamento de operadores, competências definidas, certificação",
      "imperativeChecks": "Verificar cobertura de operadores e atualização do treinamento",
      "riskSummary": "Operadores não qualificados não detectam erros de IA",
      "frameworks": ["EU AI Act Art. 14", "NIST AI RMF - GOVERN 5.3"]
    },
    {
      "questionId": "HUMAN-03-Q04",
      "subcatId": "HUMAN-03",
      "domainId": "HUMAN",
      "questionText": "Existe mecanismo de desligamento de emergência (kill switch) para IA crítica?",
      "expectedEvidence": "Procedimento de desligamento, testes realizados, responsáveis autorizados",
      "imperativeChecks": "Verificar tempo de acionamento e impacto em sistemas dependentes",
      "riskSummary": "Sem kill switch, IA problemática não pode ser parada rapidamente",
      "frameworks": ["EU AI Act Art. 14", "NIST AI RMF - MANAGE 4.2"]
    }
  ]
}
